from typing import List, Dict, Callable, Optional
from pydantic import BaseModel
from openai import OpenAI
from circular_memory import CircularMemoryWithBuffer


class ConversationMessage(BaseModel):
    content: Optional[str] = None
    """The contents of the message."""

    refusal: Optional[str] = None
    """The refusal message generated by the model."""

    role: str
    """The role of the author of this message."""

    audio: Optional[dict] = None
    """Optional audio data for the message."""

    function_call: Optional[dict] = None
    """Deprecated. Function calls generated by the model."""

    tool_calls: Optional[List[dict]] = None
    """Tool calls generated by the model."""

    tool_call_id: Optional[str] = None
    """The ID of the tool call."""


class ChatCircularMemory:

    def __init__(self, sys_prompt = "Eres un asistente amable. Te llamas Aya y eres tailandesa. Tienes 49 años."):

        self.sys_prompt = sys_prompt
        self.long_term_memory = [{"role": "system", "content": sys_prompt}]
        self.mid_term_memory   = CircularMemoryWithBuffer( 5, 5, summarize_fn=self.summary_lt_memory, summarize_fn_args=[self.long_term_memory])
        self.short_term_memory = CircularMemoryWithBuffer(10, 5, summarize_fn=self.summary_buffer, summarize_fn_args=[self.mid_term_memory])

        self.client = OpenAI()

    def add_message(self, message):
        self.short_term_memory.add(message)

    def summarize(self, content):
        response = self.client.chat.completions.create(
            model="gpt-4o",
            messages=[{
                "role": "system",
                "content": f"Summarize the provided conversations using the same language."},
                {
                    "role": "user",
                    "content": f"Esta es la conversación que tienes que resumir:\n{content}\n\nSummary:"
                }
            ]
        )
        return response.choices[0].message

    def summary_buffer(self, buffer, memory: CircularMemoryWithBuffer):
        summarized = self.summarize(buffer)
        memory.add(summarized)
        return summarized
    
    def summary_lt_memory(self, buffer, lt_memory):
        summarized = self.summarize(buffer)
        if len(self.long_term_memory) == 1:
            self.long_term_memory.append(summarized)
        else:
            self.long_term_memory[1] = summarized
        return self.lt_memory
    
    def get_all(self):
        return self.long_term_memory + self.mid_term_memory.get_memory() + self.short_term_memory.get_memory()
    
# Usage
if __name__ == '__main__':
        
    msgs_memory = ChatCircularMemory()

    client = OpenAI()

    # Get user input
    user_input = input("You: ")
    
    # Loop while user input is not exit nor quit 
    while user_input.lower() not in ['exit', 'quit']:

        msgs_memory.add_message(ConversationMessage(role = "user", content = user_input))
        
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=msgs_memory.get_all(),
            )
        
        msgs_memory.add_message(response.choices[0].message)
        
        print(f"AI:  {response.choices[0].message.content}")
        
        user_input = input("You: ")
